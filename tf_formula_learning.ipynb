{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formula learning\n",
    "\n",
    "A toy example to learn a formula to predict a synthetic data\n",
    "\n",
    "\n",
    "Let's say we have a regression problem to predict a target value in $\\cal{R}$. \n",
    "Input data has $M$ features and a target is computed as \n",
    "$$\n",
    "y_{i} = f(\\mathbf x)\n",
    "$$\n",
    "we will try various functions $f$ to observe ability to learn it using a DNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A warm-up\n",
    "\n",
    "Let us predict a simple function : $f(\\mathbf x) = 1 + \\sum_{i} x_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "n_samples = 10000\n",
    "n_features = 10\n",
    "x_max = 100.0\n",
    "x_min = -100.0\n",
    "trainval_x = (x_max - x_min) * np.random.rand(n_samples, n_features) + x_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.sum(x) + 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainval_y = np.zeros((n_samples, 1))\n",
    "for i, x in enumerate(trainval_x):\n",
    "    trainval_y[i, 0] = f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "cols_x = ['x_%i' % i for i in range(n_features)]\n",
    "df = pd.DataFrame(data=trainval_x, columns=cols_x)\n",
    "df['y'] = trainval_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.054250</td>\n",
       "      <td>50.134801</td>\n",
       "      <td>96.489763</td>\n",
       "      <td>7.089261</td>\n",
       "      <td>38.986139</td>\n",
       "      <td>-86.762398</td>\n",
       "      <td>55.862913</td>\n",
       "      <td>47.181368</td>\n",
       "      <td>88.022041</td>\n",
       "      <td>-25.991511</td>\n",
       "      <td>298.066626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-87.292284</td>\n",
       "      <td>-42.900217</td>\n",
       "      <td>-76.103046</td>\n",
       "      <td>81.735033</td>\n",
       "      <td>-83.107648</td>\n",
       "      <td>-20.600981</td>\n",
       "      <td>41.325052</td>\n",
       "      <td>-93.166873</td>\n",
       "      <td>-18.234053</td>\n",
       "      <td>3.522978</td>\n",
       "      <td>-293.822038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.027464</td>\n",
       "      <td>34.152320</td>\n",
       "      <td>-78.129135</td>\n",
       "      <td>27.059043</td>\n",
       "      <td>-83.253513</td>\n",
       "      <td>16.115477</td>\n",
       "      <td>73.580661</td>\n",
       "      <td>-88.589513</td>\n",
       "      <td>55.237234</td>\n",
       "      <td>-53.380339</td>\n",
       "      <td>-66.180301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-24.761810</td>\n",
       "      <td>-22.662519</td>\n",
       "      <td>75.383783</td>\n",
       "      <td>-45.765628</td>\n",
       "      <td>28.233258</td>\n",
       "      <td>17.865662</td>\n",
       "      <td>-70.400187</td>\n",
       "      <td>70.471372</td>\n",
       "      <td>85.252332</td>\n",
       "      <td>41.742039</td>\n",
       "      <td>156.358301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43.674722</td>\n",
       "      <td>37.147448</td>\n",
       "      <td>99.193343</td>\n",
       "      <td>28.908645</td>\n",
       "      <td>-80.307012</td>\n",
       "      <td>-64.212609</td>\n",
       "      <td>-66.084258</td>\n",
       "      <td>46.724981</td>\n",
       "      <td>-3.246206</td>\n",
       "      <td>23.917858</td>\n",
       "      <td>66.716912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x_0        x_1        x_2        x_3        x_4        x_5  \\\n",
       "0  26.054250  50.134801  96.489763   7.089261  38.986139 -86.762398   \n",
       "1 -87.292284 -42.900217 -76.103046  81.735033 -83.107648 -20.600981   \n",
       "2  30.027464  34.152320 -78.129135  27.059043 -83.253513  16.115477   \n",
       "3 -24.761810 -22.662519  75.383783 -45.765628  28.233258  17.865662   \n",
       "4  43.674722  37.147448  99.193343  28.908645 -80.307012 -64.212609   \n",
       "\n",
       "         x_6        x_7        x_8        x_9           y  \n",
       "0  55.862913  47.181368  88.022041 -25.991511  298.066626  \n",
       "1  41.325052 -93.166873 -18.234053   3.522978 -293.822038  \n",
       "2  73.580661 -88.589513  55.237234 -53.380339  -66.180301  \n",
       "3 -70.400187  70.471372  85.252332  41.742039  156.358301  \n",
       "4 -66.084258  46.724981  -3.246206  23.917858   66.716912  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(298.06662638060578, -293.82203823883231)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, ['x_%i' % i for i in range(10)]].sum() + 1.0, df.loc[1, ['x_%i' % i for i in range(10)]].sum() + 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAAEFCAYAAAAG1ep2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x90d9d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAFyCAYAAAD22xxLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBgAAACRRGAMAAACSKIwBAAAASdL/AwyXqjhcwrNHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x951ee48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "df['y'].hist(bins=100)\n",
    "plt.title('Y')\n",
    "plt.subplot(122)\n",
    "df['y'].apply(np.log).hist(bins=100)\n",
    "plt.title('Y')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(n_features):\n",
    "    plt.subplot(2, n_features/2, i+1)\n",
    "    df['x_%i' % i].hist(bins=100)\n",
    "    plt.title('x_%i' % i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a NN\n",
    "\n",
    "\n",
    "Let's define a model as  \n",
    "$$\n",
    "f_{nn}(\\mathbf x) = b_i + \\langle W_i, \\mathbf x \\rangle,\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tf_bike.train import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn(x):    \n",
    "    b = tf.Variable(tf.random_uniform((1,)), name='b')\n",
    "    W = tf.Variable(tf.random_uniform((x.get_shape().as_list()[1], 1)), name='W') \n",
    "    return tf.add(b, tf.matmul(x, W), name='trivial_regression_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_loss(y_true, y_pred):\n",
    "    return np.mean(np.mean(np.power(y_true - y_pred, 2.0), axis=-1))\n",
    "\n",
    "def tf_loss(Y_true, Y_pred):\n",
    "    return tf.reduce_mean(tf.reduce_mean(tf.square(Y_true - Y_pred), axis=-1))\n",
    "\n",
    "def tf_rmse(Y_true, Y_pred):\n",
    "    return tf.reduce_mean(tf.sqrt(tf.reduce_mean(tf.square(Y_true - Y_pred), axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss numpy : 2.36026936027\n",
      "Loss tf : 2.36027\n",
      "RMSE : 1.25758\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "y_true = np.ones((100, 1))\n",
    "y_pred = np.linspace(-2, 2, num=100).reshape((100, 1))\n",
    "\n",
    "lss = np_loss(y_true, y_pred)\n",
    "\n",
    "with tf.Session() as sess:    \n",
    "    Y_true = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "    Y_pred = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "    lss2, rmse = sess.run([tf_loss(Y_true, Y_pred), tf_rmse(Y_true, Y_pred)], feed_dict={Y_true: y_true, Y_pred: y_pred})\n",
    "\n",
    "print(\"Loss numpy :\", lss)\n",
    "print(\"Loss tf :\", lss2)\n",
    "print(\"RMSE :\", rmse)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "trainer = Trainer(log_dir='logs_{}'.format(datetime.now().strftime(\"%Y-%m-%d-%H-%M\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_params = {        \n",
    "    # Network\n",
    "    'network': nn,\n",
    "    \n",
    "    # Loss\n",
    "    'loss': tf_loss,\n",
    "    \n",
    "    # Optimizer\n",
    "    'optimizer': tf.train.GradientDescentOptimizer,\n",
    "    \n",
    "    # Metrics\n",
    "    'metrics': [\n",
    "        ('rmse', tf_rmse),\n",
    "    ],\n",
    "    \n",
    "    # Learning rate params\n",
    "    'lr': tf.train.piecewise_constant,\n",
    "    'lr_kwargs': {\n",
    "        'boundaries': [150, 250, 350],\n",
    "        'values': [0.0001, 0.00005, 0.000001]\n",
    "    },\n",
    "    \n",
    "    # Pretrained model\n",
    "    \n",
    "    \n",
    "    'training_epochs': 600,\n",
    "    'batch_size': 512,\n",
    "    \n",
    "    'seed': 2017,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "INFO:tensorflow:Starting standard services.\n",
      "INFO:tensorflow:Saving checkpoint to path logs_2017-06-28-17-00\\train\\Model/trivial_regression_model.ckpt\n",
      "INFO:tensorflow:Starting queue runners.\n",
      "Epoch: 0100\n",
      "loss=0.384149226 | rmse=0.619286627 \n",
      "val_loss=0.384575099 | val_rmse=0.619628429 \n",
      "Epoch: 0200\n",
      "loss=0.382006454 | rmse=0.617555035 \n",
      "val_loss=0.382439487 | val_rmse=0.617903560 \n",
      "Epoch: 0300\n",
      "loss=0.379890938 | rmse=0.615842049 \n",
      "val_loss=0.380319163 | val_rmse=0.616187707 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-57edba77f0a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m trainer.train(trainval_x, trainval_y, \n\u001b[0;32m      2\u001b[0m               \u001b[0mtraining_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m               verbose=1)\n\u001b[0m",
      "\u001b[1;32mD:\\vfomin\\MyExamples\\python\\NN_tests\\tf_bike\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, trainval_x, trainval_y, training_params, verbose)\u001b[0m\n\u001b[0;32m    186\u001b[0m                 train_avg_loss, train_avg_metrics = run_epoch(train_ops,\n\u001b[0;32m    187\u001b[0m                                                               \u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m                                                               train_writer, is_training_phase=True)\n\u001b[0m\u001b[0;32m    189\u001b[0m                 val_avg_loss, val_avg_metrics = run_epoch(val_ops,\n\u001b[0;32m    190\u001b[0m                                                           \u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\vfomin\\MyExamples\\python\\NN_tests\\tf_bike\\train.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[1;34m(ops, _x, _y, _writer, is_training_phase)\u001b[0m\n\u001b[0;32m    146\u001b[0m                     \u001b[1;31m# Run optimization op (backprop), loss op (to get loss value)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m                     \u001b[1;31m# and summary nodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m                     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_true\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m                     \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mops_loss_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m                     \u001b[0msummary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mops_loss_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\vfomin\\myexamples\\venv3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\vfomin\\myexamples\\venv3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\vfomin\\myexamples\\venv3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32md:\\vfomin\\myexamples\\venv3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\vfomin\\myexamples\\venv3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(trainval_x, trainval_y, \n",
    "              training_params=train_params, \n",
    "              verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Start training\n",
    "INFO:tensorflow:Restoring parameters from logs\\train\\model.ckpt\n",
    "INFO:tensorflow:Starting standard services.\n",
    "INFO:tensorflow:Saving checkpoint to path logs\\train\\model.ckpt\n",
    "INFO:tensorflow:Starting queue runners.\n",
    "Epoch: 0100\n",
    "loss=0.074179735 | rmse=0.270994010 \n",
    "val_loss=0.073447037 | val_rmse=0.270020314 \n",
    "Epoch: 0200\n",
    "loss=0.042360080 | rmse=0.204783824 \n",
    "val_loss=0.041942643 | val_rmse=0.204050232 \n",
    "Epoch: 0300\n",
    "loss=0.024189908 | rmse=0.154751265 \n",
    "val_loss=0.023950804 | val_rmse=0.154194623 \n",
    "Epoch: 0400\n",
    "loss=0.013813899 | rmse=0.116943221 \n",
    "val_loss=0.013677813 | val_rmse=0.116524741 \n",
    "Epoch: 0500\n",
    "loss=0.007888554 | rmse=0.088372299 \n",
    "val_loss=0.007810403 | val_rmse=0.088053277 \n",
    "Epoch: 0600\n",
    "loss=0.004504888 | rmse=0.066782001 \n",
    "val_loss=0.004460046 | val_rmse=0.066539340 \n",
    "Optimization Finished!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct model and encapsulating all ops into scopes, making\n",
    "# Tensorboard's Graph visualization more convenient\n",
    "with tf.name_scope('Model'):\n",
    "    # Model    \n",
    "    Y_pred = nn(X)\n",
    "    \n",
    "with tf.name_scope('Loss'):\n",
    "    # Minimize error using MAE\n",
    "    loss = tf_loss(Y_true, Y_pred)\n",
    "    \n",
    "with tf.name_scope('Optimizer'):\n",
    "    # Gradient Descent\n",
    "    global_step = tf.Variable(0, trainable=False)    \n",
    "    lr_f = train_params['lr_f'](global_step, **train_params['lr_kwargs'])    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(lr_f).minimize(loss)\n",
    "    \n",
    "with tf.name_scope('RMSE'):    \n",
    "    rmse = tf_rmse(Y_true, Y_pred)\n",
    "\n",
    "# Create a summary to monitor loss tensor\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "# Create a summary to monitor RMSE tensor\n",
    "tf.summary.scalar(\"RMSE\", rmse)\n",
    "# Merge all summaries into a single op\n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "verbose = 1\n",
    "display_step = 100\n",
    "\n",
    "# Launch the graph\n",
    "print(\"Start training\")\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())    \n",
    "    # op to write logs to Tensorboard\n",
    "    summary_writer = tf.summary.FileWriter(train_params['logs_path'], graph=sess.graph)\n",
    "\n",
    "    \n",
    "    batch_size = train_params['batch_size']        \n",
    "    train_x, val_x, train_y, val_y = train_test_split(trainval_x, trainval_y, train_size=0.75)\n",
    "    \n",
    "    n_train_batchs = int(train_x.shape[0]/batch_size)\n",
    "    n_val_batchs = int(val_x.shape[0]/batch_size)    \n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(train_params['training_epochs']):\n",
    "               \n",
    "        if verbose > 0 and (epoch+1) % display_step == 0:\n",
    "            print(\"Epoch: %04d\" % (epoch+1))\n",
    "        \n",
    "        avg_loss = 0.0\n",
    "        avg_rmse = 0.0\n",
    "        # Train over all batches            \n",
    "        for i in range(n_train_batchs):\n",
    "\n",
    "            if verbose > 1:\n",
    "                print(\"-- %i / %i\" % (i, n_train_batchs))\n",
    "\n",
    "            \n",
    "            i_start = batch_size*i\n",
    "            i_end = batch_size*(i+1)\n",
    "            batch_xs, batch_ys = train_x[i_start:i_end,:], train_y[i_start:i_end, :] \n",
    "            # Run optimization op (backprop), loss op (to get loss value)\n",
    "            # and summary nodes\n",
    "            _, l, r, y_pred, summary = sess.run([optimizer, loss, rmse, Y_pred, merged_summary_op],\n",
    "                                                feed_dict={X: batch_xs, Y_true: batch_ys})\n",
    "            \n",
    "            if verbose > 2:\n",
    "                print(\"Numpy Loss: %f\" % np_loss(batch_ys, y_pred))\n",
    "                print(\"TF Loss: %f\" % l)\n",
    "                print(\"TF RMSE: %f\" % r)\n",
    "                \n",
    "            # Write logs at every iteration\n",
    "            summary_writer.add_summary(summary, epoch * n_train_batchs + i)\n",
    "            \n",
    "            # Compute average loss\n",
    "            avg_loss += l * 1.0 / n_train_batchs\n",
    "            avg_rmse += r * 1.0 / n_train_batchs            \n",
    "            \n",
    "        # Display logs per epoch step\n",
    "        if verbose > 0 and (epoch+1) % display_step == 0:\n",
    "            print(\"loss=%.9f, rmse=%.9f\" % (avg_loss, avg_rmse))\n",
    "        \n",
    "        # Validation\n",
    "        avg_loss = 0.0\n",
    "        avg_rmse = 0.0        \n",
    "        for i in range(n_val_batchs):\n",
    "            i_start = batch_size*i\n",
    "            i_end = batch_size*(i+1)\n",
    "            batch_xs, batch_ys = val_x[i_start:i_end,:], val_y[i_start:i_end, :] \n",
    "            # Run optimization op (backprop), loss op (to get loss value)\n",
    "            # and summary nodes\n",
    "            run_options = None\n",
    "            run_metadata = None\n",
    "            if i % 100 == 99:\n",
    "                run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "                run_metadata = tf.RunMetadata()\n",
    "            \n",
    "            l, r, summary = sess.run([loss, rmse, merged_summary_op], \n",
    "                                     feed_dict={X: batch_xs, Y_true: batch_ys}, \n",
    "                                     run_metadata=run_metadata, options=run_options)\n",
    "            # Compute average loss\n",
    "            avg_loss += l / n_val_batchs\n",
    "            avg_rmse += r / n_val_batchs            \n",
    "            \n",
    "        # Display logs per epoch step\n",
    "        if verbose > 0 and (epoch+1) % display_step == 0:\n",
    "            print(\"val_loss=%.9f, val_rmse=%.9f\" % (avg_loss, avg_rmse))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    \n",
    "    B = sess.graph.get_tensor_by_name('Model/b:0')\n",
    "    Weights = sess.graph.get_tensor_by_name('Model/W:0')\n",
    "    b, weights = sess.run([B, Weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A ratio-like and squared formula\n",
    "\n",
    "Let $M=10$ and the function to learn is defined as \n",
    "$$\n",
    "f(\\mathbf x) = \\frac{\\sum_i a_i x_i + b} {\\sum_i c_i x_i + d} + \\alpha \\sum_{i,j \\neq i} x_i x_j + \\beta\n",
    "$$\n",
    "where coefficients $a_i$, $b$, $c_i$, $d$, $\\alpha$, $\\beta$ are randomly chosen.\n",
    "\n",
    "Setup input data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "n_samples = 10000\n",
    "n_features = 10\n",
    "a = np.random.rand(n_features)\n",
    "b = 1.0\n",
    "c = np.random.rand(n_features)\n",
    "d = np.random.rand() * 100.0\n",
    "alpha = np.random.rand() * 1.0 / 50.0\n",
    "beta = np.random.rand() * 50.0\n",
    "\n",
    "x_max = 100.0\n",
    "x_min = -50.0\n",
    "trainval_x = (x_max - x_min) * np.random.rand(n_samples, n_features) + x_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(sample_x):\n",
    "    numerator = np.dot(a, sample_x) + b\n",
    "    denominator = np.dot(c, sample_x) + d\n",
    "    t1 = numerator / denominator\n",
    "    \n",
    "    t2 = 0\n",
    "    for v in sample_x:\n",
    "        t2 += v * (np.sum(sample_x) - v)    \n",
    "    t2 *= alpha\n",
    "    return t1 + t2 + beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainval_y = np.zeros((n_samples, 1))\n",
    "for i, x in enumerate(trainval_x):\n",
    "    trainval_y[i] = f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "cols_x = ['x_%i' % i for i in range(n_features)]\n",
    "df = pd.DataFrame(data=trainval_x, columns=cols_x)\n",
    "df['y'] = trainval_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "df['y'].hist(bins=100)\n",
    "plt.title('Y')\n",
    "plt.subplot(122)\n",
    "df['y'].apply(np.log).hist(bins=100)\n",
    "plt.title('Y')\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# for i in range(n_features):\n",
    "#     plt.subplot(2, n_features/2, i+1)\n",
    "#     df['x_%i' % i].hist(bins=100)\n",
    "#     plt.title('x_%i' % i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a NN\n",
    "\n",
    "\n",
    "Let's define a model as  \n",
    "$$\n",
    "f_{nn}(\\mathbf x) = \\prod_{i=0}^{l-1} \\left( b_i + \\langle W_i, g(\\mathbf x) \\rangle \\right),\n",
    "$$\n",
    "where \n",
    "$$\n",
    "g(\\mathbf x) = g_m(\\mathbf x) = h^{(1)}_{m,m-1}(\\mathbf x) + \\frac{1}{\\epsilon + h^{(2)}_{m,m-1}(\\mathbf x)}\n",
    "$$\n",
    "and \n",
    "$$\n",
    "h^{(i)}_{m,m-1}(\\mathbf x) = \\text{activation}(\\langle W_{i,m}, g_{m-1}(\\mathbf x) \\rangle + b_{i,m}), \\\\\n",
    "g_{0} (\\mathbf x) = \\mathbf x\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_rmse(Y_true, Y_pred):\n",
    "    return tf.reduce_mean(tf.sqrt(tf.reduce_mean(tf.square(Y_true - Y_pred), axis=-1)))\n",
    "\n",
    "def tf_loss(Y_true, Y_pred):\n",
    "    l1 = tf.reduce_mean(tf.reduce_mean(tf.square(Y_true - Y_pred), axis=-1))\n",
    "    l2 = tf.log(1.0 + tf_rmse(Y_true, Y_pred))\n",
    "    return tf.minimum(l1, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    n = 100\n",
    "    Y_true = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "    Y_pred = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "    loss = np.zeros((n,))\n",
    "    yspan = np.linspace(-20, 20, num=n)\n",
    "    for i, v in enumerate(yspan):\n",
    "        y_true = np.ones((1, 1))\n",
    "        y_pred = np.array(v).reshape((1, 1))\n",
    "        loss[i] = sess.run(tf_loss(Y_true, Y_pred), feed_dict={Y_true: y_true, Y_pred: y_pred})\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(yspan, loss, label='loss')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features))\n",
    "Y_true = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "\n",
    "train_params = {    \n",
    "    \n",
    "#     'lr_kwargs': {\n",
    "#         'boundaries': [50, 100, 200, 500, 1000, ],\n",
    "#         'values': [1e-3, 1e-4, 5*1e-5, 0.000001, 0.0000001]\n",
    "#     },\n",
    "#     'lr_f': tf.train.piecewise_constant,        \n",
    "    \n",
    "    'lr_kwargs': {\n",
    "        'decay_steps': 100,\n",
    "        'decay_rate': 0.9,\n",
    "        'learning_rate': 0.005,\n",
    "        'staircase': True\n",
    "    },\n",
    "    'lr_f': lambda x, **kwargs: tf.train.exponential_decay(global_step=x, **kwargs),\n",
    "    \n",
    "    'training_epochs': 5000,\n",
    "    'batch_size': 1024,\n",
    "    \n",
    "    'seed': 2017,\n",
    "    \n",
    "    # Tensorboard\n",
    "    'logs_path': 'logs'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epsilon = tf.constant(1e-10)\n",
    "\n",
    "def h(index, m, x, n_filters, with_activation=True):    \n",
    "    b = tf.Variable(tf.random_uniform([n_filters]), \n",
    "                    name='bias_%i_%i' % (index, m))\n",
    "    W = tf.Variable(tf.random_uniform(shape=[x.get_shape().as_list()[1], n_filters]), \n",
    "                    name=\"W_%i_%i\" % (index, m))\n",
    "    \n",
    "    name = name='h_%i_%i' % (index, m)\n",
    "    out = tf.add(tf.matmul(x, W), b)\n",
    "    if with_activation:\n",
    "        return tf.nn.elu(out, name=name)\n",
    "    else:\n",
    "        return tf.identity(out, name=name)\n",
    "    \n",
    "    \n",
    "def g(m, x, n_filters_list):        \n",
    "    _x = x if m == 0 else g(m-1, x, n_filters_list)\n",
    "    inv_h2 = tf.divide(tf.constant(1.0), tf.add(epsilon, h(2, m, _x, n_filters_list[m])))\n",
    "    return tf.add(h(1, m, _x, n_filters_list[m]), inv_h2, name='g_%i' % m)\n",
    "\n",
    "\n",
    "def nn(x, k, m):    \n",
    "    nf = 5\n",
    "    n_filters_list = [nf for j in range(m)]       \n",
    "    net = h(3, 0, g(m-1, x, n_filters_list), n_filters=1, with_activation=False)\n",
    "    for i in range(1, k):\n",
    "        n_filters_list = [nf for j in range(m)]               \n",
    "        net = tf.multiply(net, h(3, 0, g(m-1, x, n_filters_list), n_filters=1, with_activation=False))\n",
    "    return net\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct model and encapsulating all ops into scopes, making\n",
    "# Tensorboard's Graph visualization more convenient\n",
    "with tf.name_scope('Model'):\n",
    "    # Model\n",
    "    Y_pred = nn(X, k=2, m=3)\n",
    "    \n",
    "with tf.name_scope('Loss'):\n",
    "    # Minimize error using MAE\n",
    "    loss = tf_loss(Y_true, Y_pred)\n",
    "    \n",
    "with tf.name_scope('Optimizer'):\n",
    "    # Gradient Descent\n",
    "    global_step = tf.Variable(0, trainable=False)    \n",
    "    lr_f = train_params['lr_f'](global_step, **train_params['lr_kwargs'])    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(lr_f).minimize(loss)\n",
    "    \n",
    "with tf.name_scope('RMSE'):\n",
    "    # Accuracy    \n",
    "    rmse = tf_rmse(Y_true, Y_pred)\n",
    "\n",
    "# Create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "# Create a summary to monitor accuracy tensor\n",
    "tf.summary.scalar(\"RMSE\", rmse)\n",
    "# Merge all summaries into a single op\n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "verbose = 1\n",
    "display_step = 10\n",
    "\n",
    "# Launch the graph\n",
    "tf.set_random_seed(train_params['seed'])\n",
    "print(\"Start training\")\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())    \n",
    "    # op to write logs to Tensorboard\n",
    "    summary_writer = tf.summary.FileWriter(os.path.join(train_params['logs_path'], \n",
    "                                                        'run_%s' % str(datetime.now().strftime(\"%Y-%m-%d-%H-%M\"))), \n",
    "                                           graph=sess.graph)\n",
    "\n",
    "    \n",
    "    batch_size = train_params['batch_size']        \n",
    "    train_x, val_x, train_y, val_y = train_test_split(trainval_x, trainval_y, train_size=0.75)\n",
    "    \n",
    "    n_train_batchs = int(train_x.shape[0]/batch_size)\n",
    "    n_val_batchs = int(val_x.shape[0]/batch_size)    \n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(train_params['training_epochs']):\n",
    "               \n",
    "        if verbose > 0 and (epoch+1) % display_step == 0:\n",
    "            print(\"Epoch: %04d\" % (epoch+1))\n",
    "        \n",
    "        avg_loss = 0.0\n",
    "        avg_rmse = 0.0\n",
    "        # Train over all batches\n",
    "        lr = sess.run(lr_f, feed_dict={global_step: epoch})\n",
    "        for i in range(n_train_batchs):\n",
    "\n",
    "            if verbose > 1:\n",
    "                print(\"-- %i / %i\" % (i, n_train_batchs))\n",
    "\n",
    "            \n",
    "            i_start = batch_size*i\n",
    "            i_end = batch_size*(i+1)\n",
    "            batch_xs, batch_ys = train_x[i_start:i_end,:], train_y[i_start:i_end, :] \n",
    "            # Run optimization op (backprop), loss op (to get loss value)\n",
    "            # and summary nodes\n",
    "            run_options = None\n",
    "            run_metadata = None\n",
    "            if i % 100 == 99:\n",
    "                run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "                run_metadata = tf.RunMetadata()\n",
    "            _, l, r, y_pred, summary = sess.run([optimizer, loss, rmse, Y_pred, merged_summary_op],\n",
    "                                                feed_dict={X: batch_xs, Y_true: batch_ys}, \n",
    "                                                run_metadata=run_metadata, options=run_options)\n",
    "            \n",
    "            if verbose > 2:\n",
    "                print(\"Numpy Loss: %f\" % np_loss(batch_ys, y_pred))\n",
    "                print(\"TF Loss: %f\" % l)\n",
    "                print(\"TF RMSE: %f\" % r)\n",
    "                \n",
    "            # Write logs at every iteration\n",
    "            summary_writer.add_summary(summary, epoch * n_train_batchs + i)\n",
    "            \n",
    "            # Compute average loss\n",
    "            avg_loss += l * 1.0 / n_train_batchs\n",
    "            avg_rmse += r * 1.0 / n_train_batchs            \n",
    "            \n",
    "        # Display logs per epoch step\n",
    "        if verbose > 0 and (epoch+1) % display_step == 0:\n",
    "            print(\"loss=%.9f, rmse=%.9f | lr=%f\" % (avg_loss, avg_rmse, lr))\n",
    "        \n",
    "        # Validation\n",
    "        avg_loss = 0.0\n",
    "        avg_rmse = 0.0        \n",
    "        for i in range(n_val_batchs):\n",
    "            i_start = batch_size*i\n",
    "            i_end = batch_size*(i+1)\n",
    "            batch_xs, batch_ys = val_x[i_start:i_end,:], val_y[i_start:i_end, :] \n",
    "            # Run optimization op (backprop), loss op (to get loss value)\n",
    "            # and summary nodes\n",
    "            run_options = None\n",
    "            run_metadata = None\n",
    "            if i % 100 == 99:\n",
    "                run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "                run_metadata = tf.RunMetadata()\n",
    "            \n",
    "            l, r, summary = sess.run([loss, rmse, merged_summary_op], \n",
    "                                     feed_dict={X: batch_xs, Y_true: batch_ys}, \n",
    "                                     run_metadata=run_metadata, options=run_options)\n",
    "            # Compute average loss\n",
    "            avg_loss += l / n_val_batchs\n",
    "            avg_rmse += r / n_val_batchs            \n",
    "            \n",
    "        # Display logs per epoch step\n",
    "        if verbose > 0 and (epoch+1) % display_step == 0:\n",
    "            print(\"val_loss=%.9f, val_rmse=%.9f\" % (avg_loss, avg_rmse))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
